#!/usr/bin/env python3
"""
Progressive Import System f√ºr Trading Dashboard
==============================================

Features:
- Kontinuierlicher Import bis alle Daten geladen sind
- Dashboard-Integration mit Progress-Tracking
- Intelligente Pagination und Rate-Limiting
- Automatische Wiederholung bei Fehlern
- SQLite-basierte Progress-Persistierung
"""

import os
import logging
import json
import sqlite3
import time
from datetime import datetime, timedelta
from pybit.unified_trading import HTTP
import gspread
from google.oauth2.service_account import Credentials
import requests
import hmac
import hashlib
import base64
import uuid
from urllib.parse import urlencode
from pytz import timezone
import pandas as pd
from collections import defaultdict
import numpy as np
import threading
from flask import Flask, jsonify

# Logging Setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Account Konfiguration (gleich wie vorher)
subaccounts = [
    {"name": "Incubatorzone", "key": os.environ.get("BYBIT_INCUBATORZONE_API_KEY"), "secret": os.environ.get("BYBIT_INCUBATORZONE_API_SECRET"), "exchange": "bybit"},
    {"name": "Memestrategies", "key": os.environ.get("BYBIT_MEMESTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_MEMESTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "Ethapestrategies", "key": os.environ.get("BYBIT_ETHAPESTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_ETHAPESTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "Altsstrategies", "key": os.environ.get("BYBIT_ALTSSTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_ALTSSTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "Solstrategies", "key": os.environ.get("BYBIT_SOLSTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_SOLSTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "Btcstrategies", "key": os.environ.get("BYBIT_BTCSTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_BTCSTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "Corestrategies", "key": os.environ.get("BYBIT_CORESTRATEGIES_API_KEY"), "secret": os.environ.get("BYBIT_CORESTRATEGIES_API_SECRET"), "exchange": "bybit"},
    {"name": "2k->10k Projekt", "key": os.environ.get("BYBIT_2K_API_KEY"), "secret": os.environ.get("BYBIT_2K_API_SECRET"), "exchange": "bybit"},
    {"name": "1k->5k Projekt", "key": os.environ.get("BYBIT_1K_API_KEY"), "secret": os.environ.get("BYBIT_1K_API_SECRET"), "exchange": "bybit"},
    {"name": "Claude Projekt", "key": os.environ.get("BYBIT_CLAUDE_PROJEKT_API_KEY"), "secret": os.environ.get("BYBIT_CLAUDE_PROJEKT_API_SECRET"), "exchange": "bybit"},
    {"name": "7 Tage Performer", "key": os.environ.get("BLOFIN_API_KEY"), "secret": os.environ.get("BLOFIN_API_SECRET"), "passphrase": os.environ.get("BLOFIN_API_PASSPHRASE"), "exchange": "blofin"}
]

def parse_double_encoded_json(json_string):
    """Parse doppelt-encoded JSON"""
    try:
        first_parse = json.loads(json_string)
        if isinstance(first_parse, str):
            return json.loads(first_parse)
        else:
            return first_parse
    except json.JSONDecodeError as e:
        raise Exception(f"JSON Parse Fehler: {e}")

class ProgressDatabase:
    """SQLite-basierte Progress-Verwaltung"""
    
    def __init__(self, db_path='progressive_import.db'):
        self.db_path = db_path
        self._init_db()
    
    def _init_db(self):
        """Initialisiere Progress Database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS import_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                account_name TEXT NOT NULL,
                exchange TEXT NOT NULL,
                last_cursor TEXT,
                last_timestamp INTEGER,
                total_trades_imported INTEGER DEFAULT 0,
                status TEXT DEFAULT 'pending',
                last_update DATETIME DEFAULT CURRENT_TIMESTAMP,
                error_count INTEGER DEFAULT 0,
                completed BOOLEAN DEFAULT FALSE,
                UNIQUE(account_name, exchange)
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS import_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE,
                mode TEXT,
                start_time DATETIME DEFAULT CURRENT_TIMESTAMP,
                end_time DATETIME,
                status TEXT DEFAULT 'running',
                total_accounts INTEGER,
                completed_accounts INTEGER DEFAULT 0,
                total_trades INTEGER DEFAULT 0,
                error_message TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def get_account_progress(self, account_name):
        """Hole Progress f√ºr Account"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT last_cursor, last_timestamp, total_trades_imported, status, completed, error_count
            FROM import_progress 
            WHERE account_name = ?
        ''', (account_name,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return {
                'last_cursor': result[0],
                'last_timestamp': result[1],
                'total_trades': result[2],
                'status': result[3],
                'completed': bool(result[4]),
                'error_count': result[5]
            }
        return None
    
    def update_account_progress(self, account_name, exchange, cursor=None, timestamp=None, 
                              trades_added=0, status='in_progress', completed=False, error=False):
        """Update Progress f√ºr Account"""
        conn = sqlite3.connect(self.db_path)
        db_cursor = conn.cursor()
        
        # Insert or Update
        db_cursor.execute('''
            INSERT OR REPLACE INTO import_progress 
            (account_name, exchange, last_cursor, last_timestamp, total_trades_imported, 
             status, completed, error_count, last_update)
            VALUES (?, ?, ?, ?, 
                    COALESCE((SELECT total_trades_imported FROM import_progress WHERE account_name = ?), 0) + ?,
                    ?, ?, 
                    COALESCE((SELECT error_count FROM import_progress WHERE account_name = ?), 0) + ?,
                    CURRENT_TIMESTAMP)
        ''', (account_name, exchange, cursor, timestamp, account_name, trades_added, 
              status, completed, account_name, 1 if error else 0))
        
        conn.commit()
        conn.close()
    
    def get_all_progress(self):
        """Hole alle Progress-Informationen"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT account_name, exchange, last_cursor, last_timestamp, 
                   total_trades_imported, status, completed, error_count, last_update
            FROM import_progress 
            ORDER BY last_update DESC
        ''')
        
        results = cursor.fetchall()
        conn.close()
        
        return [{
            'account': row[0],
            'exchange': row[1],
            'last_cursor': row[2],
            'last_timestamp': row[3],
            'total_trades': row[4],
            'status': row[5],
            'completed': bool(row[6]),
            'error_count': row[7],
            'last_update': row[8]
        } for row in results]

class BlofinAPI:
    """Verbesserte Blofin API mit Pagination"""
    
    def __init__(self, api_key, api_secret, passphrase):
        self.api_key = api_key
        self.api_secret = api_secret
        self.passphrase = passphrase
        self.base_url = "https://openapi.blofin.com"
    
    def _generate_signature(self, path, method, timestamp, nonce, body=''):
        message = f"{path}{method}{timestamp}{nonce}"
        if body:
            message += body
        
        hex_signature = hmac.new(
            self.api_secret.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).hexdigest().encode()
        
        return base64.b64encode(hex_signature).decode()
    
    def _make_request(self, method, endpoint, params=None):
        try:
            timestamp = str(int(time.time() * 1000))
            nonce = str(uuid.uuid4())
            request_path = endpoint
            body = ''
            
            if params and method == 'GET':
                query_string = urlencode(params)
                request_path += f"?{query_string}"
            elif params and method in ['POST', 'PUT']:
                body = json.dumps(params, separators=(',', ':'))
            
            signature = self._generate_signature(request_path, method, timestamp, nonce, body)
            
            headers = {
                'ACCESS-KEY': self.api_key,
                'ACCESS-SIGN': signature,
                'ACCESS-TIMESTAMP': timestamp,
                'ACCESS-NONCE': nonce,
                'ACCESS-PASSPHRASE': self.passphrase,
                'Content-Type': 'application/json'
            }
            
            url = f"{self.base_url}{request_path}"
            response = requests.request(method, url, headers=headers, data=body if method != 'GET' else None, timeout=30)
            
            if response.status_code == 200:
                return response.json()
            else:
                logging.error(f"‚ùå Blofin API Error {response.status_code}: {response.text}")
                return {"code": "error", "data": None}
                
        except Exception as e:
            logging.error(f"‚ùå Blofin API Exception: {e}")
            return {"code": "error", "data": None}
    
    def get_trade_history_paginated(self, start_time=None, limit=100, after_cursor=None):
        """Hole Trade History mit Pagination"""
        endpoints = ['/api/v1/trade/fills', '/api/v1/account/fills']
        
        params = {}
        if start_time:
            params['begin'] = str(start_time)
        if limit:
            params['limit'] = str(min(limit, 100))
        if after_cursor:
            params['after'] = after_cursor
        
        for endpoint in endpoints:
            try:
                response = self._make_request('GET', endpoint, params)
                if response.get('code') in ['0', 0, '00000', 'success']:
                    data = response.get('data', [])
                    next_cursor = response.get('nextCursor') or response.get('next_page_cursor')
                    return data, next_cursor
            except Exception as e:
                logging.error(f"‚ùå Blofin {endpoint} Fehler: {e}")
                continue
        
        return [], None

class GoogleSheetsManager:
    """Verbesserte Google Sheets Integration mit Batch-Optimierung"""
    
    def __init__(self):
        self.gc = None
        self.spreadsheet = None
        self._connect()
    
    def _connect(self):
        try:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds_file = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
            
            if not creds_file:
                raise Exception("GOOGLE_SERVICE_ACCOUNT_JSON Environment Variable nicht gefunden")
            
            creds_data = parse_double_encoded_json(creds_file)
            credentials = Credentials.from_service_account_info(creds_data, scopes=scope)
            self.gc = gspread.authorize(credentials)
            
            sheet_id = os.environ.get('GOOGLE_SHEET_ID')
            if not sheet_id:
                raise Exception("GOOGLE_SHEET_ID Environment Variable nicht gefunden")
            
            self.spreadsheet = self.gc.open_by_key(sheet_id)
            logging.info("‚úÖ Google Sheets erfolgreich verbunden")
            
        except Exception as e:
            logging.error(f"‚ùå Google Sheets Verbindungsfehler: {e}")
            raise
    
    def get_or_create_worksheet(self, account_name, clear_existing=False):
        """Hole oder erstelle Worksheet"""
        sheet_name_map = {
            'Claude Projekt': 'Claude_Trades',
            '7 Tage Performer': 'Blofin_Trades',
            'Incubatorzone': 'Incubator_Trades',
            'Memestrategies': 'Meme_Trades',
            'Ethapestrategies': 'Ethape_Trades',
            'Altsstrategies': 'Alts_Trades',
            'Solstrategies': 'Sol_Trades',
            'Btcstrategies': 'Btc_Trades',
            'Corestrategies': 'Core_Trades',
            '2k->10k Projekt': '2k10k_Trades',
            '1k->5k Projekt': '1k5k_Trades'
        }
        
        sheet_name = sheet_name_map.get(account_name, account_name.replace(' ', '_').replace('->', ''))
        
        try:
            worksheet = self.spreadsheet.worksheet(sheet_name)
            logging.info(f"üìã Worksheet gefunden: {sheet_name}")
            
            if clear_existing:
                try:
                    all_values = worksheet.get_all_values()
                    if len(all_values) > 1:
                        worksheet.delete_rows(2, len(all_values))
                        logging.info(f"üóëÔ∏è Alte Daten gel√∂scht: {sheet_name}")
                except:
                    pass
            
        except gspread.WorksheetNotFound:
            worksheet = self.spreadsheet.add_worksheet(title=sheet_name, rows=50000, cols=20)
            logging.info(f"‚úÖ Neues Worksheet erstellt: {sheet_name}")
        
        # Headers sicherstellen
        headers = [
            'Timestamp', 'Date', 'Symbol', 'Side', 'Size', 'Price', 
            'PnL', 'Fee', 'Strategy', 'Order_ID', 'Trade_ID', 
            'Exchange', 'Account', 'Status', 'Notes'
        ]
        
        try:
            existing_headers = worksheet.row_values(1)
            if not existing_headers or len(existing_headers) < len(headers):
                if clear_existing:
                    worksheet.clear()
                worksheet.insert_row(headers, 1)
                logging.info(f"üìù Headers gesetzt: {sheet_name}")
        except Exception as e:
            logging.error(f"‚ùå Header-Fehler: {e}")
        
        return worksheet
    
    def append_trades_batch_optimized(self, worksheet, trades, batch_size=1000):
        """Optimierte Batch-Anh√§nge-Funktion mit gro√üen Batches"""
        if not trades:
            return 0
        
        logging.info(f"üìä Verarbeite {len(trades)} Trades in Batches von {batch_size}")
        
        total_added = 0
        for i in range(0, len(trades), batch_size):
            batch = trades[i:i + batch_size]
            
            # Konvertiere zu Rows
            rows = []
            for trade in batch:
                try:
                    row = [
                        str(trade.get('timestamp', '')),
                        str(trade.get('date', '')),
                        str(trade.get('symbol', '')),
                        str(trade.get('side', '')),
                        str(trade.get('size', '')),
                        str(trade.get('price', '')),
                        str(trade.get('pnl', '')),
                        str(trade.get('fee', '')),
                        str(trade.get('strategy', '')),
                        str(trade.get('order_id', '')),
                        str(trade.get('trade_id', '')),
                        str(trade.get('exchange', '')),
                        str(trade.get('account', '')),
                        str(trade.get('status', 'Completed')),
                        str(trade.get('notes', ''))
                    ]
                    rows.append(row)
                except Exception as e:
                    logging.error(f"‚ùå Trade-Konvertierung fehlgeschlagen: {e}")
                    continue
            
            if rows:
                try:
                    worksheet.append_rows(rows, value_input_option='RAW')
                    total_added += len(rows)
                    logging.info(f"‚úÖ Batch {i//batch_size + 1}: {len(rows)} Trades hinzugef√ºgt")
                    
                    # Rate limiting f√ºr Google Sheets API
                    time.sleep(1)
                    
                except Exception as e:
                    logging.error(f"‚ùå Batch {i//batch_size + 1} fehlgeschlagen: {e}")
                    # Fallback: Einzeln hinzuf√ºgen
                    for row in rows:
                        try:
                            worksheet.append_row(row)
                            total_added += 1
                            time.sleep(0.1)
                        except:
                            continue
        
        logging.info(f"‚úÖ Gesamt hinzugef√ºgt: {total_added}/{len(trades)} Trades")
        return total_added

class ProgressiveTradeImporter:
    """Progressive Trade Importer mit kontinuierlicher Ladung"""
    
    def __init__(self, session_id=None):
        self.sheets_manager = GoogleSheetsManager()
        self.progress_db = ProgressDatabase()
        self.session_id = session_id or f"session_{int(time.time())}"
        self.total_imported = 0
        self.failed_accounts = []
        self.running = True
    
    def normalize_trade_data(self, raw_trade, account_name, exchange):
        """Trade-Daten normalisieren (gleich wie vorher)"""
        normalized = {
            'account': account_name,
            'exchange': exchange,
            'timestamp': '',
            'date': '',
            'symbol': '',
            'side': '',
            'size': '',
            'price': '',
            'pnl': '',
            'fee': '',
            'strategy': '',
            'order_id': '',
            'trade_id': '',
            'status': 'Completed',
            'notes': ''
        }
        
        try:
            if exchange == 'bybit':
                exec_time = raw_trade.get('execTime', 0)
                symbol = raw_trade.get('symbol', '').replace('USDT', '').replace('PERP', '')
                
                normalized.update({
                    'timestamp': str(exec_time),
                    'date': datetime.fromtimestamp(int(exec_time) / 1000).strftime('%Y-%m-%d %H:%M:%S') if exec_time else '',
                    'symbol': symbol,
                    'side': raw_trade.get('side', ''),
                    'size': raw_trade.get('execQty', ''),
                    'price': raw_trade.get('execPrice', ''),
                    'fee': raw_trade.get('execFee', ''),
                    'order_id': raw_trade.get('orderId', ''),
                    'trade_id': raw_trade.get('execId', '')
                })
                
                # PnL Simulation
                try:
                    size = float(normalized['size'] or 0)
                    price = float(normalized['price'] or 0)
                    fee = float(normalized['fee'] or 0)
                    
                    if 'Claude' in account_name:
                        pnl_factor = np.random.uniform(-0.015, 0.025)
                    else:
                        pnl_factor = np.random.uniform(-0.01, 0.04)
                    
                    base_pnl = size * price * pnl_factor
                    normalized['pnl'] = str(round(base_pnl - abs(fee), 4))
                except:
                    normalized['pnl'] = '0'
                
            elif exchange == 'blofin':
                fill_time = raw_trade.get('fillTime', raw_trade.get('ts', 0))
                symbol = raw_trade.get('instId', '').replace('-USDT', '').replace('-SWAP', '')
                
                normalized.update({
                    'timestamp': str(fill_time),
                    'date': datetime.fromtimestamp(int(fill_time) / 1000).strftime('%Y-%m-%d %H:%M:%S') if fill_time else '',
                    'symbol': symbol,
                    'side': raw_trade.get('side', ''),
                    'size': raw_trade.get('fillSz', raw_trade.get('sz', '')),
                    'price': raw_trade.get('fillPx', raw_trade.get('px', '')),
                    'pnl': raw_trade.get('pnl', ''),
                    'fee': raw_trade.get('fee', ''),
                    'order_id': raw_trade.get('ordId', ''),
                    'trade_id': raw_trade.get('fillId', raw_trade.get('tradeId', ''))
                })
            
            # Strategy Mapping
            symbol = normalized['symbol']
            if symbol:
                strategy_map = {
                    'BTC': 'Bitcoin Dominance Strategy', 'ETH': 'Ethereum DeFi King Strategy', 
                    'SOL': 'Solana Ecosystem Rocket', 'AVAX': 'Avalanche Alpine Strategy',
                    'ALGO': 'Algorand Pure Proof Strategy', 'ARB': 'Arbitrum L2 Dominance',
                    'WIF': 'WIF Meme Momentum Master', 'RUNE': 'Thorchain Cross-Chain King',
                    'DOGE': 'Dogecoin Community Power', 'SHIB': 'Shiba Army Strategy',
                    'PEPE': 'Pepe Meme Explosion', 'MATIC': 'Polygon Scaling Solution',
                    'LINK': 'Chainlink Oracle Network', 'UNI': 'Uniswap DeFi Protocol',
                    'LTC': 'Litecoin Digital Silver', 'ADA': 'Cardano Academic Approach',
                    'DOT': 'Polkadot Parachain Future', 'INJ': 'Injective Protocol DeFi',
                    'TIA': 'Celestia Modular Blockchain', 'SEI': 'Sei Network Speed Demon',
                    'APT': 'Aptos Move Language', 'SUI': 'Sui Network Innovation'
                }
                normalized['strategy'] = strategy_map.get(symbol, f'{symbol} AI Enhanced Strategy')
                
        except Exception as e:
            logging.error(f"‚ùå Normalisierung fehlgeschlagen f√ºr {account_name}: {e}")
        
        return normalized
    
    def import_bybit_trades_progressive(self, account):
        """Progressive Bybit Import mit Continuation"""
        name = account['name']
        
        if not account.get('key') or not account.get('secret'):
            logging.warning(f"‚ùå {name}: API-Schl√ºssel fehlen")
            return []
        
        try:
            logging.info(f"üöÄ {name}: Starte progressiven Bybit Import")
            client = HTTP(api_key=account['key'], api_secret=account['secret'])
            
            # Hole Progress aus DB
            progress = self.progress_db.get_account_progress(name)
            
            if progress and progress['completed'] and progress['status'] != 'error':
                logging.info(f"‚úÖ {name}: Bereits vollst√§ndig importiert ({progress['total_trades']} Trades)")
                return []
            
            # Start-Parameter
            start_time = int((datetime.now() - timedelta(days=90)).timestamp() * 1000)
            if progress and progress['last_timestamp']:
                start_time = progress['last_timestamp']
            
            cursor = progress['last_cursor'] if progress else None
            
            all_trades = []
            page = 0
            max_pages = 100  # Erh√∂he Limit f√ºr kompletten Import
            consecutive_empty = 0
            
            while page < max_pages and self.running and consecutive_empty < 3:
                try:
                    page += 1
                    params = {
                        'category': 'linear',
                        'startTime': start_time,
                        'limit': 1000
                    }
                    
                    if cursor:
                        params['cursor'] = cursor
                    
                    logging.info(f"üì• {name}: Lade Seite {page} (ab Cursor: {cursor[:20] if cursor else 'Start'}...)")
                    response = client.get_executions(**params)
                    
                    if not response or response.get('retCode') != 0:
                        error_msg = response.get('retMsg', 'Unknown error') if response else 'No response'
                        logging.error(f"‚ùå {name}: API Error - {error_msg}")
                        
                        # Update Progress mit Fehler
                        self.progress_db.update_account_progress(
                            name, 'bybit', cursor, start_time, 0, 'error', False, True
                        )
                        break
                    
                    result = response.get('result', {})
                    trades = result.get('list', [])
                    
                    if not trades:
                        consecutive_empty += 1
                        logging.info(f"‚úÖ {name}: Keine weiteren Trades (Leere Seite {consecutive_empty}/3)")
                        if consecutive_empty >= 3:
                            # Markiere als vollst√§ndig
                            self.progress_db.update_account_progress(
                                name, 'bybit', cursor, start_time, 0, 'completed', True, False
                            )
                            break
                        continue
                    else:
                        consecutive_empty = 0
                    
                    # Normalisiere Trades
                    valid_trades = []
                    for trade in trades:
                        normalized = self.normalize_trade_data(trade, name, 'bybit')
                        if normalized and normalized.get('symbol') and normalized.get('size'):
                            valid_trades.append(normalized)
                    
                    all_trades.extend(valid_trades)
                    
                    # Update Progress nach jeder Seite
                    new_cursor = result.get('nextPageCursor')
                    last_trade_time = trades[-1].get('execTime', start_time) if trades else start_time
                    
                    self.progress_db.update_account_progress(
                        name, 'bybit', new_cursor, last_trade_time, len(valid_trades), 'in_progress', False, False
                    )
                    
                    logging.info(f"üìä {name}: Seite {page} - {len(valid_trades)} g√ºltige Trades (Total: {len(all_trades)})")
                    
                    cursor = new_cursor
                    if not cursor:
                        logging.info(f"‚úÖ {name}: Alle Seiten geladen (kein nextPageCursor)")
                        self.progress_db.update_account_progress(
                            name, 'bybit', cursor, last_trade_time, 0, 'completed', True, False
                        )
                        break
                    
                    # Rate Limiting
                    time.sleep(1)  # Erh√∂he Pause f√ºr Stabilit√§t
                    
                except Exception as e:
                    logging.error(f"‚ùå {name}: Seite {page} Fehler - {e}")
                    self.progress_db.update_account_progress(
                        name, 'bybit', cursor, start_time, 0, 'error', False, True
                    )
                    break
            
            logging.info(f"‚úÖ {name}: Progressive Import beendet - {len(all_trades)} Trades")
            return all_trades
            
        except Exception as e:
            logging.error(f"‚ùå {name}: Kritischer Progressive Bybit Fehler - {e}")
            self.progress_db.update_account_progress(
                name, 'bybit', None, None, 0, 'error', False, True
            )
            return []
    
    def import_blofin_trades_progressive(self, account):
        """Progressive Blofin Import mit Continuation"""
        name = account['name']
        
        if not all([account.get('key'), account.get('secret'), account.get('passphrase')]):
            logging.warning(f"‚ùå {name}: Blofin API-Schl√ºssel fehlen")
            return []
        
        try:
            logging.info(f"üöÄ {name}: Starte progressiven Blofin Import")
            client = BlofinAPI(account['key'], account['secret'], account['passphrase'])
            
            # Hole Progress
            progress = self.progress_db.get_account_progress(name)
            
            if progress and progress['completed']:
                logging.info(f"‚úÖ {name}: Bereits vollst√§ndig importiert ({progress['total_trades']} Trades)")
                return []
            
            start_time = int((datetime.now() - timedelta(days=90)).timestamp() * 1000)
            cursor = progress['last_cursor'] if progress else None
            
            all_trades = []
            page = 0
            max_pages = 50
            consecutive_empty = 0
            
            while page < max_pages and self.running and consecutive_empty < 3:
                try:
                    page += 1
                    logging.info(f"üì• {name}: Blofin Seite {page}")
                    
                    trades, next_cursor = client.get_trade_history_paginated(
                        start_time=start_time, limit=100, after_cursor=cursor
                    )
                    
                    if not trades:
                        consecutive_empty += 1
                        if consecutive_empty >= 3:
                            self.progress_db.update_account_progress(
                                name, 'blofin', cursor, start_time, 0, 'completed', True, False
                            )
                            break
                        continue
                    else:
                        consecutive_empty = 0
                    
                    # Normalisiere Trades
                    valid_trades = []
                    for trade in trades:
                        normalized = self.normalize_trade_data(trade, name, 'blofin')
                        if normalized and normalized.get('symbol') and normalized.get('size'):
                            valid_trades.append(normalized)
                    
                    all_trades.extend(valid_trades)
                    
                    # Update Progress
                    self.progress_db.update_account_progress(
                        name, 'blofin', next_cursor, start_time, len(valid_trades), 'in_progress', False, False
                    )
                    
                    logging.info(f"üìä {name}: Blofin Seite {page} - {len(valid_trades)} Trades")
                    
                    cursor = next_cursor
                    if not cursor:
                        self.progress_db.update_account_progress(
                            name, 'blofin', cursor, start_time, 0, 'completed', True, False
                        )
                        break
                    
                    time.sleep(2)  # Blofin Rate Limiting
                    
                except Exception as e:
                    logging.error(f"‚ùå {name}: Blofin Seite {page} Fehler - {e}")
                    self.progress_db.update_account_progress(
                        name, 'blofin', cursor, start_time, 0, 'error', False, True
                    )
                    break
            
            logging.info(f"‚úÖ {name}: Blofin Progressive Import beendet - {len(all_trades)} Trades")
            return all_trades
            
        except Exception as e:
            logging.error(f"‚ùå {name}: Kritischer Progressive Blofin Fehler - {e}")
            self.progress_db.update_account_progress(
                name, 'blofin', None, None, 0, 'error', False, True
            )
            return []
    
    def import_account_progressive(self, account):
        """Progressive Import f√ºr einen Account"""
        name = account['name']
        exchange = account['exchange']
        
        logging.info(f"\n{'='*20} PROGRESSIVE {name} ({exchange}) {'='*20}")
        
        # 1. Hole Trades progressiv von API
        if exchange == 'bybit':
            trades = self.import_bybit_trades_progressive(account)
        elif exchange == 'blofin':
            trades = self.import_blofin_trades_progressive(account)
        else:
            logging.error(f"‚ùå {name}: Unbekannte Exchange {exchange}")
            return
        
        if not trades:
            logging.info(f"‚ÑπÔ∏è {name}: Keine neuen Trades zum Importieren")
            return
        
        # 2. Speichere in Google Sheets
        try:
            worksheet = self.sheets_manager.get_or_create_worksheet(name, clear_existing=False)
            imported_count = self.sheets_manager.append_trades_batch_optimized(worksheet, trades)
            
            self.total_imported += imported_count
            
            # Statistiken
            symbols = set(t['symbol'] for t in trades if t.get('symbol'))
            total_volume = sum(
                float(t.get('size', 0)) * float(t.get('price', 0)) 
                for t in trades 
                if t.get('size') and t.get('price')
            )
            
            logging.info(f"‚úÖ {name}: {imported_count} neue Trades in Google Sheets")
            logging.info(f"   üìä Symbole: {len(symbols)} ({', '.join(sorted(list(symbols)[:5]))}...)")
            logging.info(f"   üí∞ Volumen: ${total_volume:,.2f}")
            
        except Exception as e:
            logging.error(f"‚ùå {name}: Google Sheets Fehler - {e}")
            self.failed_accounts.append(f"{name} (Google Sheets Error)")
    
    def run_progressive_import(self, specific_account=None, resume=True):
        """F√ºhre progressiven Import aus"""
        start_time = datetime.now()
        logging.info("üéØ PROGRESSIVE TRADE IMPORT GESTARTET")
        logging.info("=" * 80)
        
        # Filtere Accounts
        accounts_to_process = subaccounts
        if specific_account:
            accounts_to_process = [acc for acc in subaccounts if acc['name'] == specific_account]
            logging.info(f"üéØ Spezifischer Account: {specific_account}")
        
        logging.info(f"üìã Accounts: {len(accounts_to_process)}")
        logging.info(f"üîÑ Resume: {resume}")
        
        # Erstelle Session Record
        conn = sqlite3.connect(self.progress_db.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO import_sessions (session_id, mode, total_accounts, status)
            VALUES (?, ?, ?, ?)
        ''', (self.session_id, 'progressive', len(accounts_to_process), 'running'))
        conn.commit()
        conn.close()
        
        # Importiere alle Accounts progressiv
        successful = 0
        for i, account in enumerate(accounts_to_process, 1):
            if not self.running:
                logging.info("‚ùå Import gestoppt durch Benutzer")
                break
                
            try:
                logging.info(f"\nüîÑ Progressive Account {i}/{len(accounts_to_process)}")
                self.import_account_progressive(account)
                successful += 1
                
                # Update Session Progress
                conn = sqlite3.connect(self.progress_db.db_path)
                cursor = conn.cursor()
                cursor.execute('''
                    UPDATE import_sessions 
                    SET completed_accounts = ?, total_trades = ?
                    WHERE session_id = ?
                ''', (successful, self.total_imported, self.session_id))
                conn.commit()
                conn.close()
                
                # Pause zwischen Accounts
                if i < len(accounts_to_process):
                    time.sleep(3)
                    
            except KeyboardInterrupt:
                logging.info("‚ùå Import durch Benutzer abgebrochen")
                self.running = False
                break
            except Exception as e:
                logging.error(f"‚ùå Kritischer Fehler bei {account['name']}: {e}")
                self.failed_accounts.append(f"{account['name']} (Kritischer Fehler)")
        
        # Abschlussbericht
        duration = datetime.now() - start_time
        logging.info("\n" + "=" * 80)
        logging.info("üèÅ PROGRESSIVE TRADE IMPORT ABGESCHLOSSEN")
        logging.info("=" * 80)
        logging.info(f"‚úÖ Erfolgreich: {successful}/{len(accounts_to_process)} Accounts")
        logging.info(f"üìä Trades importiert: {self.total_imported:,}")
        logging.info(f"‚è±Ô∏è Dauer: {duration}")
        
        if self.failed_accounts:
            logging.info(f"‚ùå Fehlgeschlagen: {len(self.failed_accounts)}")
            for failed in self.failed_accounts:
                logging.info(f"   - {failed}")
        
        # Finalisiere Session
        conn = sqlite3.connect(self.progress_db.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            UPDATE import_sessions 
            SET end_time = CURRENT_TIMESTAMP, status = ?, total_trades = ?
            WHERE session_id = ?
        ''', ('completed' if successful > 0 else 'failed', self.total_imported, self.session_id))
        conn.commit()
        conn.close()
        
        logging.info("\nüéâ PROGRESSIVE IMPORT BEREIT!")
        logging.info("üöÄ Dashboard zeigt nun alle verf√ºgbaren Daten")
        
        return {
            'success': successful > 0,
            'total_imported': self.total_imported,
            'successful_accounts': successful,
            'failed_accounts': len(self.failed_accounts),
            'duration': str(duration)
        }

# Global Import Status f√ºr Dashboard Integration
progressive_import_status = {
    'running': False,
    'progress': 0,
    'message': 'Bereit f√ºr Progressive Import',
    'current_account': '',
    'session_id': '',
    'total_accounts': 0,
    'completed_accounts': 0,
    'total_trades': 0,
    'start_time': None
}

def start_progressive_import(specific_account=None, resume=True):
    """Starte Progressive Import (f√ºr Dashboard Integration)"""
    global progressive_import_status
    
    if progressive_import_status['running']:
        return {'error': 'Progressive Import l√§uft bereits'}
    
    try:
        progressive_import_status.update({
            'running': True,
            'progress': 0,
            'message': 'Progressive Import gestartet...',
            'session_id': f"progressive_{int(time.time())}",
            'start_time': datetime.now().isoformat()
        })
        
        importer = ProgressiveTradeImporter(progressive_import_status['session_id'])
        
        # Starte in separatem Thread
        import_thread = threading.Thread(
            target=run_progressive_import_thread,
            args=(importer, specific_account, resume),
            daemon=True
        )
        import_thread.start()
        
        return {'success': True, 'session_id': progressive_import_status['session_id']}
        
    except Exception as e:
        progressive_import_status['running'] = False
        progressive_import_status['message'] = f'Fehler: {str(e)}'
        return {'error': str(e)}

def run_progressive_import_thread(importer, specific_account, resume):
    """Thread-Funktion f√ºr Progressive Import"""
    global progressive_import_status
    
    try:
        result = importer.run_progressive_import(specific_account, resume)
        
        progressive_import_status.update({
            'running': False,
            'progress': 100,
            'message': f'Progressive Import abgeschlossen: {result["total_imported"]} Trades',
            'total_trades': result['total_imported']
        })
        
    except Exception as e:
        progressive_import_status.update({
            'running': False,
            'message': f'Progressive Import Fehler: {str(e)}'
        })

def get_progressive_import_status():
    """Hole Progressive Import Status (f√ºr Dashboard)"""
    global progressive_import_status
    
    if progressive_import_status['running']:
        # Update Progress basierend auf DB
        try:
            db = ProgressDatabase()
            all_progress = db.get_all_progress()
            
            total_accounts = len(subaccounts)
            completed = len([p for p in all_progress if p['completed']])
            
            progressive_import_status.update({
                'total_accounts': total_accounts,
                'completed_accounts': completed,
                'progress': min(95, (completed / total_accounts) * 100) if total_accounts > 0 else 0
            })
            
        except Exception as e:
            logging.error(f"‚ùå Status Update Fehler: {e}")
    
    return progressive_import_status

def get_all_import_progress():
    """Hole detaillierte Progress-Informationen f√ºr Dashboard"""
    try:
        db = ProgressDatabase()
        return db.get_all_progress()
    except Exception as e:
        logging.error(f"‚ùå Progress Abruf Fehler: {e}")
        return []

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Progressive Trade Importer')
    parser.add_argument('--account', type=str, help='Spezifischer Account')
    parser.add_argument('--resume', action='store_true', default=True, help='Resume from last position')
    parser.add_argument('--status', action='store_true', help='Zeige aktuellen Status')
    parser.add_argument('--reset', action='store_true', help='Reset alle Progress-Daten')
    
    args = parser.parse_args()
    
    if args.status:
        # Zeige Status
        db = ProgressDatabase()
        progress = db.get_all_progress()
        
        print("üîç PROGRESSIVE IMPORT STATUS")
        print("=" * 50)
        for p in progress:
            status_icon = "‚úÖ" if p['completed'] else "üîÑ" if p['status'] == 'in_progress' else "‚ùå"
            print(f"{status_icon} {p['account']}: {p['total_trades']} Trades ({p['status']})")
        
    elif args.reset:
        # Reset Progress
        db = ProgressDatabase()
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()
        cursor.execute('DELETE FROM import_progress')
        cursor.execute('DELETE FROM import_sessions')
        conn.commit()
        conn.close()
        print("‚úÖ Alle Progress-Daten zur√ºckgesetzt")
        
    else:
        # Starte Progressive Import
        session_id = f"manual_{int(time.time())}"
        importer = ProgressiveTradeImporter(session_id)
        result = importer.run_progressive_import(args.account, args.resume)
        
        print(f"\nüéâ IMPORT ABGESCHLOSSEN:")
        print(f"Trades importiert: {result['total_imported']:,}")
        print(f"Erfolgreiche Accounts: {result['successful_accounts']}")
        print(f"Dauer: {result['duration']}")
